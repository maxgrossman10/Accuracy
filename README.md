Accuracy is used to evaluate the performance of classification models, which involve predicting the correct label for input data. To use accuracy as a metric for a classification model, the dataset should be balanced, meaning there's roughly an equal number of data points for each class. If the data is not balanced, we pivot towards precision, recall, and F1-scores. We'll kick off with a straightforward classification example.
Imagine you have a classification model you want to use for the data in the graph below, and there's a new, previously unseen data point represented by the gold star. The question becomes, "Should this new data point be classified as belonging to Class A or Class B?"

In this scenario, our model predicts the new data point as Class B. After making this assignment, we can evaluate the performance of our supervised model by comparing the classification to the true label found in the test set. If the label is truly B we have an accuracy of 1.0, if not, our accuracy is 0.
Now, let's create a classification model using arthritis data generated randomly using Numpy's random number generator. Yellow points represent patients with arthritis, and blue points represent those without arthritis. 
We'll first conduct an 80–20 train-test split with our data. 80% of the data will be used to train our classification model and the remaining 20% of the data will serve as our independent test set and represents the gold star we saw in the simple example. I show the test points for each class so one see where the analogous gold stars lie (red and yellow dots here). 

Our classification model uses probability. When applied to test observations, the model estimates the probability that a given data point belongs to either of the two classes. In the figure below, I display the probabilities that each test point belongs to Class 1,  although the model generates the probabilities for both classes.
To make a definitive classification, we utilize a threshold of 0.5, which means if the calculated probability exceeds this threshold, the data point is assigned to Class 1.
Our model achieved an accuracy score of 95%, which means we got 1/20 wrong.
However, it's important to know whether this incorrect prediction corresponds to a Type 1 or Type 2 error.
